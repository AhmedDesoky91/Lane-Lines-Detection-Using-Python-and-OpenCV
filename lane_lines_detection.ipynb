{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Lane Lines Detection Using Python and OpenCV**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In this project, I have detected lane lines on the road using _Python_ and _OpenCV_.**\n",
    "\n",
    "**I have developed a computer vision pipeline that processes a group of test images then applied this pipeline to two test video streams.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Architecture:\n",
    "\n",
    "1. Load test images\n",
    "2. Apply grayscale transform\n",
    "3. Smooth the image to suppress noise and any spurious gradients\n",
    "4. Apply Canny edge detection algorithm\n",
    "5. Cut-out any edges that are out of the lane lines region (**region of interest**)\n",
    "6. Get the lines located in the region of interest using hough transform\n",
    "7. Fitting and extrapolating these lines for both right and left lane\n",
    "  * Determining the x and y points of each of the right and left lane lines\n",
    "  * Extrapolating or fitting these points for both lane lines\n",
    "8. Draw the lane lines on the original image\n",
    "  * Drawing the lane lines on a blank image firstly\n",
    "  * Weighting the original image with the lane lines image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment:\n",
    "* Ubuntu 16.04 LTS\n",
    "* Python 3.6.4\n",
    "* OpenCV 3.1.0\n",
    "* Anaconda 4.4.10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing some useful packages\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "import os\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load test images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test images are loaded to a list `test_images` which will be used to feed our pipeline which test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_list = os.listdir(\"test_images/\")\n",
    "test_images = []\n",
    "for img in images_list:\n",
    "    test_images.append(mpimg.imread(\"test_images/\"+img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Apply grayscale transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grayscale(image):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "        Applies the gray-scale transform\n",
    "    Parameters:\n",
    "        image: A color input image\n",
    "    Output:\n",
    "        A gray-scaled image\n",
    "    \"\"\"\n",
    "    return cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Smooth the image to suppress noise and any spurious gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_blur(image, kernel_size = 5):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "        Smoothes the image by applying guassian filter to the image\n",
    "    Parameters:\n",
    "        image: A gray-scaled input image\n",
    "        kernel_size (Default = 5): This is the window the convolves the whole image applying the filter to the image\n",
    "    Output:\n",
    "        Smoothed (Averaged or Filtered) image\n",
    "    \"\"\"\n",
    "    \n",
    "    return cv2.GaussianBlur(image, (kernel_size, kernel_size), 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Apply Canny edge detection algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Wikipedia**\n",
    "\n",
    "The Canny edge detector is an edge detection operator that uses a multi-stage algorithm to detect a wide range of edges in images.\n",
    "\n",
    "**Process of Canny edge detection algorithm**\n",
    "\n",
    "1. Apply Gaussian filter to smooth the image in order to remove the noise\n",
    "2. Find the intensity gradients of the image\n",
    "3. Apply non-maximum suppression to get rid of spurious response to edge detection\n",
    "4. Apply double threshold to determine potential edges\n",
    "5. Track edge by hysteresis: Finalize the detection of edges by suppressing all the other edges that are weak and not connected to strong edges.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def canny(image, low_threshold  = 50, high_threshold = 150):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "        Canny edge detector which detects strong edges (strong gradients pixels) above the high threshold and \n",
    "        rejects pixels below the low threshold. Pixels with values between low and high thresholds will be included\n",
    "        as long as they are connected to strong edges\n",
    "    Parameters:\n",
    "        image: The input gray-scaled smoothed image\n",
    "        low_thresold (Default = 50): The threshold  value of rejecting pixel\n",
    "        high_threshold (Default = 150): The threshold of strong edges in the image\n",
    "    Output:\n",
    "        A binary image with pixels tracing out the detected edges and black everything else\n",
    "    \"\"\"\n",
    "    \n",
    "    return cv2.Canny(image, low_threshold, high_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Cut-out any edges that are out of the lane lines region (region of interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def region_of_interest(image):\n",
    "    \"\"\"\n",
    "    Descrition:\n",
    "        Applies an image mask.Only keeps the region of the image defined by the polygon\n",
    "        formed from `vertices`. The rest of the image is set to black.\n",
    "    Paramteres:\n",
    "        image: The image from Canny edge detector\n",
    "    Output:\n",
    "        An image that has the edges in the defined polygon and black everywhere else\n",
    "    \"\"\"\n",
    "    \n",
    "    image_shape  = image.shape\n",
    "    # The following points are the vertices points of the polygon\n",
    "    bottom_left  = (110,image_shape[0])\n",
    "    up_left      = (450, image_shape[0]/1.65)\n",
    "    bottom_right = (image_shape[1]-450, image_shape[0]/1.65)\n",
    "    up_right     = (image_shape[1]-20,image_shape[0])\n",
    "    vertices     = np.array([[bottom_left, up_left, bottom_right, up_right]], dtype=np.int32)\n",
    "    \n",
    "    #defining a blank mask to start with\n",
    "    mask = np.zeros_like(image)   \n",
    "    \n",
    "    #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(image.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "        \n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    \n",
    "    #returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(image, mask)\n",
    "    return masked_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Get the lines located in the region of interest using hough transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hough_transform(image):\n",
    "    \"\"\"\n",
    "    Descrition:\n",
    "        Hough Transfrom is used to indetify lines located in the region of interest\n",
    "    Parameters:\n",
    "        image: This is the output a Canny transform and after applying the region of interest mask.\n",
    "    Output:\n",
    "        Returns a list with hough lines.\n",
    "    \"\"\"\n",
    "    rho = 1 # distance resolution in pixels of the Hough grid\n",
    "    theta = (np.pi/180) # angular resolution in radians of the Hough grid\n",
    "    threshold = 10     # minimum number of votes (intersections in Hough grid cell)\n",
    "    min_line_length = 1 #minimum number of pixels making up a line\n",
    "    max_line_gap = 1    # maximum gap in pixels between connectable line segments\n",
    "    lines = cv2.HoughLinesP(image, rho, theta, threshold, np.array([]), minLineLength=min_line_length, maxLineGap=max_line_gap)\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Fitting and extrapolating these lines for both right and left lane"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step is done into two mian steps:\n",
    "* Determining the x and y points of each the right and left lane lines\n",
    "* Extrapolating or fitting these points for both lane lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determining the x and y points of the right lane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_right_lane_points(lines_image):\n",
    "    \"\"\"\n",
    "    Descrition:\n",
    "        This function calculates the slope of each line detected from hough transform. \n",
    "        If the slope is +ve, then this line belongs to the right lane.\n",
    "        Note: 0.4 is selected for better filteration of the lines ouput\n",
    "    Parameters:\n",
    "        lines_image: This is the output of hough tranfrom (a list contains the hough lines)\n",
    "    Output\n",
    "        right_lane_x_points: a list contains the all x points of the right lane\n",
    "        right_lane_y_points: a list contains the all y points of the right lane\n",
    "    \"\"\"\n",
    "    \n",
    "    right_lane_x_points = []\n",
    "    right_lane_y_points = []\n",
    "    \n",
    "    for line in lines_image:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            slope = (y2 - y1) / (x2 - x1)\n",
    "            if(slope > 0.4): #+ve slope -> right lane\n",
    "                #print(\"Right Lane Detected\\n\")\n",
    "                right_lane_x_points.append(x1)\n",
    "                right_lane_x_points.append(x2)\n",
    "                right_lane_y_points.append(y1)\n",
    "                right_lane_y_points.append(y2)\n",
    "                \n",
    "    return right_lane_x_points, right_lane_y_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determining the x and y points of the left lane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_left_lane_points(lines_image):\n",
    "    \"\"\"\n",
    "    Descrition:\n",
    "        This function calculates the slope of each line detected from hough transform. \n",
    "        If the slope is -ve, then this line belongs to the left lane.\n",
    "        Note: -0.6 is selected for better filteration of the lines ouput\n",
    "    Parameters:\n",
    "        lines_image: This is the output of hough tranfrom (a list contains the hough lines)\n",
    "    Output\n",
    "        left_lane_x_points: a list contains the all x points of the left lane\n",
    "        left_lane_y_points: a list contains the all y points of the left lane\n",
    "    \"\"\"\n",
    "    \n",
    "    left_lane_x_points  = []\n",
    "    left_lane_y_points  = []\n",
    "\n",
    "    for line in lines_image:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            slope = (y2 - y1) / (x2 - x1)\n",
    "            if(slope < -0.6): #-ve slope -> left lane\n",
    "                #print(\"Left Lane Detected\\n\")\n",
    "                left_lane_x_points.append(x1)\n",
    "                left_lane_x_points.append(x2)\n",
    "                left_lane_y_points.append(y1)\n",
    "                left_lane_y_points.append(y2)\n",
    "                    \n",
    "    return left_lane_x_points, left_lane_y_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extrapolating or fitting the points for both lane lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_lane_line(lane_line_x_points, lane_line_y_points, image_shape):\n",
    "    \"\"\"\n",
    "    Descrition:\n",
    "        The function extrapolates the detectioned points in each lane from the line equation given that\n",
    "        Ymin and Ymax are defined from the region of interest.\n",
    "        IF:   y = mx + b\n",
    "        THEN: x = (y - b)/m\n",
    "    Parameters:\n",
    "        lane_line_x_points: This is a list for the x points of our intended lane line\n",
    "        lane_line_y_points: This is a list for the y points of our intended lane line\n",
    "        image_shape: The height and width of the image to get the Ymin and Ymax\n",
    "        \n",
    "    Output\n",
    "        Xmin, Ymin: The start point of our intended lane line\n",
    "        Xmax, Ymax: The end point of our intended lane line\n",
    "    \"\"\"\n",
    "    \n",
    "    #Getting the slop and intersect of the right lane line\n",
    "    fit_lane_line =  np.polyfit(lane_line_x_points, lane_line_y_points, 1)\n",
    "    m = fit_lane_line[0] # Slope\n",
    "    b = fit_lane_line[1] # Intercept\n",
    "\n",
    "    #These are the y values defined at my region of interest\n",
    "    Ymax = image_shape[0]\n",
    "    Ymin = image_shape[0]/1.65\n",
    "    \n",
    "    # If equation of a line: y = m*x + b\n",
    "    # Hence: x = (y - b)/m\n",
    "    Xmax =  (Ymax - b) / m\n",
    "    Xmin =  (Ymin - b) / m\n",
    "\n",
    "    #Converting the values from float to int to be suitable for cv2.line\n",
    "    Ymax = int(Ymax)\n",
    "    Ymin = int(Ymin)\n",
    "    Xmax = int(Xmax)\n",
    "    Xmin = int(Xmin)\n",
    "    \n",
    "    return Xmax, Xmin, Ymax, Ymin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Draw the lane lines on the original image\n",
    "\n",
    "In this step, we are:\n",
    "* Drawing the lane lines on a blank image firstly\n",
    "* Weighting the original image with the lane lines image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drawing right and left lane lines on blank image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_lines(image, Xmin, Xmax, Ymin, Ymax):\n",
    "    \"\"\"\n",
    "    Descrition:\n",
    "        This function is used to draw the lane line on a blank image       \n",
    "    Parameters:\n",
    "        Xmin, Ymin: The start point of our intended lane line\n",
    "        Xmax, Ymax: The end point of our intended lane line\n",
    "    Output:\n",
    "        Image of the lane line drawn on it\n",
    "    \"\"\"\n",
    "    \n",
    "    #Drawing the lane line on the blank image\n",
    "    return cv2.line(image,(Xmin,Ymin),(Xmax,Ymax),(255,0,0),10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighting the original image with the lane lines image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_img(image, initial_img, α=0.8, β=1., γ=0.):\n",
    "    \"\"\"\n",
    "    Descrition:\n",
    "        This function is used to weight (combine) the lane lines image and the original one\n",
    "    Parameters:\n",
    "        image: The image which has the lane lines\n",
    "        initial_img: should be the image before any processing.\n",
    "    Output:\n",
    "        image is computed as follows: initial_img * α + image * β + γ\n",
    "        \n",
    "    NOTE: initial_img and img must be the same shape!\n",
    "    \"\"\"\n",
    "    return cv2.addWeighted(initial_img, α, image, β, γ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here we save the image after the pipeline for the specified path ```test_images_output```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image(image, test_image_index):\n",
    "    \"\"\"\n",
    "    Descrition:\n",
    "        This function is save an image to the specified path with the same origianal name\n",
    "    Parameters:\n",
    "        image: should be the image after the pipeline\n",
    "        test_image_index: an index to retrieve the name of the test image under processing\n",
    "    Output:\n",
    "        Saving the image in the test_images_output directory with the same original name\n",
    "    \"\"\"\n",
    "    \n",
    "    path = 'test_images_output/'\n",
    "    cv2.imwrite(os.path.join(path , images_list[test_image_index]), cv2.cvtColor(image, cv2.COLOR_RGB2BGR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Pipeline:\n",
    "This is our algorithm pipeline entry point.\n",
    "This function wraps and calls all the functions needed to detect the lane lines on the road of an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pipeline(image):\n",
    "    \"\"\"\n",
    "    Descrition:\n",
    "        This function is save an image to the specified path with the same origianal name\n",
    "    Parameters:\n",
    "        image: image under test to detect the lane lines in it\n",
    "    Output:\n",
    "        result: The output of our pipeline. It should be the original image with the lane lines annotated.\n",
    "    \"\"\"\n",
    "    image_shape  = image.shape\n",
    "\n",
    "    gray_scale_image = grayscale(image)\n",
    "    \n",
    "    smoothed_gray_scale_image = gaussian_blur(gray_scale_image)\n",
    "    \n",
    "    edge_detected_image = canny(smoothed_gray_scale_image)\n",
    "    \n",
    "    masked_edge_detected_image = region_of_interest(edge_detected_image)\n",
    "    \n",
    "    lines_image = hough_transform(masked_edge_detected_image)\n",
    "    \n",
    "    right_lane_x_points , right_lane_y_points = get_right_lane_points(lines_image)\n",
    "    left_lane_x_points  , left_lane_y_points  = get_left_lane_points(lines_image)\n",
    "    \n",
    "    Xright_min , Xright_max , Yright_min , Yright_max = fit_lane_line(right_lane_x_points, right_lane_y_points, image_shape)\n",
    "    Xleft_min  , Xleft_max  , Yleft_min  , Yleft_max  = fit_lane_line(left_lane_x_points, left_lane_y_points, image_shape)\n",
    "    \n",
    "    \n",
    "    lane_lines_image = np.copy(image)*0  # creating a blank to draw lines on\n",
    "    lane_lines_image = draw_lines(lane_lines_image, Xright_min , Xright_max , Yright_min , Yright_max)\n",
    "    lane_lines_image = draw_lines(lane_lines_image, Xleft_min  , Xleft_max  , Yleft_min  , Yleft_max)\n",
    "    \n",
    "    result = weighted_img(lane_lines_image, image)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on Test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i , img in enumerate(test_images, start = 0):\n",
    "    result = process_pipeline(img)\n",
    "    save_image(result, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test images should now be saved at `test_images_output` folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "    \n",
    "    result = process_pipeline(image)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test solidWhiteRight.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video test_videos_output/solidWhiteRight.mp4\n",
      "[MoviePy] Writing video test_videos_output/solidWhiteRight.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 221/222 [00:07<00:00, 30.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: test_videos_output/solidWhiteRight.mp4 \n",
      "\n",
      "CPU times: user 6.21 s, sys: 225 ms, total: 6.43 s\n",
      "Wall time: 8.35 s\n"
     ]
    }
   ],
   "source": [
    "white_output = 'test_videos_output/solidWhiteRight.mp4'\n",
    "## To speed up the testing process you may want to try your pipeline on a shorter subclip of the video\n",
    "## To do so add .subclip(start_second,end_second) to the end of the line below\n",
    "## Where start_second and end_second are integer values representing the start and end of the subclip\n",
    "## You may also uncomment the following line for a subclip of the first 5 seconds\n",
    "##clip1 = VideoFileClip(\"test_videos/solidWhiteRight.mp4\").subclip(0,5)\n",
    "clip1 = VideoFileClip(\"test_videos/solidWhiteRight.mp4\")\n",
    "white_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outout video should be saved at `test_videos_output` and the file named by `solidWhiteRight.mp4`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test solidYellowLeft.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video test_videos_output/solidYellowLeft.mp4\n",
      "[MoviePy] Writing video test_videos_output/solidYellowLeft.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 681/682 [00:25<00:00, 26.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: test_videos_output/solidYellowLeft.mp4 \n",
      "\n",
      "CPU times: user 19.7 s, sys: 657 ms, total: 20.3 s\n",
      "Wall time: 26.8 s\n"
     ]
    }
   ],
   "source": [
    "yellow_output = 'test_videos_output/solidYellowLeft.mp4'\n",
    "## To speed up the testing process you may want to try your pipeline on a shorter subclip of the video\n",
    "## To do so add .subclip(start_second,end_second) to the end of the line below\n",
    "## Where start_second and end_second are integer values representing the start and end of the subclip\n",
    "## You may also uncomment the following line for a subclip of the first 5 seconds\n",
    "##clip2 = VideoFileClip('test_videos/solidYellowLeft.mp4').subclip(0,5)\n",
    "clip2 = VideoFileClip('test_videos/solidYellowLeft.mp4')\n",
    "yellow_clip = clip2.fl_image(process_image)\n",
    "%time yellow_clip.write_videofile(yellow_output, audio=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outout video should be saved at `test_videos_output` folder and the file named by `solidYellowLeft.mp4`"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
